{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as trn\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "datanumber = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "location: train train/0.jpg\n",
      "fans_number: 13600\n",
      "likes: 611\n",
      "comment_number 7\n",
      "0.0449264705882353\n",
      "(40,)\n",
      "-----------------\n",
      "location: train train/1.jpg\n",
      "fans_number: 13600\n",
      "likes: 587\n",
      "comment_number 2\n",
      "0.04316176470588235\n",
      "(40,)\n"
     ]
    }
   ],
   "source": [
    "with open ('dataset_ver2/combine.json','r',encoding=\"utf-8\") as data:\n",
    "    test=json.load(data)\n",
    "    train_data = []\n",
    "    label_data = []\n",
    "    for i in range(datanumber):\n",
    "        print(\"-----------------\")\n",
    "        print(\"location: train\",test[i][\"location\"])\n",
    "        print(\"fans_number:\",test[i][\"fans_number\"])\n",
    "        print(\"likes:\",test[i][\"likes\"])\n",
    "        print(\"comment_number\",test[i][\"comment_number\"])\n",
    "        train_data.append([test[i][\"location\"]])\n",
    "        print(int(test[i][\"likes\"])/int(test[i][\"fans_number\"]))\n",
    "        if int(test[i][\"likes\"])/(test[i][\"fans_number\"]/1000) >29:\n",
    "            a=np.eye(40,k=29)[0]\n",
    "        else:\n",
    "            a=np.eye(40,k=int(int(test[i][\"likes\"])/(int(test[i][\"fans_number\"])/1000))[0])\n",
    "        if int(test[i][\"comment_number\"])/50 >9:\n",
    "            b=np.eye(40,k=39)[0]\n",
    "        else:\n",
    "            b=np.eye(40,k=(int(int(test[i][\"comment_number\"])/50)+30))[0]\n",
    "        train_data.append(a+b)\n",
    "        print((a+b).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/test/1.jpg'],\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.]),\n",
       " ['/test/2.jpg'],\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[list(['/test/1.jpg'])\n",
      "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0.])]\n",
      " [list(['/test/2.jpg'])\n",
      "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0.])]]\n"
     ]
    }
   ],
   "source": [
    "train_data_array = np.array(train_data)\n",
    "train_data_array = train_data_array.reshape(datanumber,2)\n",
    "print(train_data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(length, num):\n",
    "    d = np.zeros(length)\n",
    "    d[num] = 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image transformer\n",
    "centre_crop = trn.Compose([\n",
    "        trn.Resize((256,256)),\n",
    "        trn.CenterCrop(224),\n",
    "        trn.ToTensor(),\n",
    "        trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIGNSDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform):\n",
    "        self.filenames = os.listdir(data_dir)\n",
    "        self.filenames = [os.path.join(data_dir, f) for f in self.filenames if f.endswith('.jpg')]\n",
    "\n",
    "        #self.labels = [int(os.path.split(filename)[-1][0]) for filename in self.filenames]\n",
    "        self.labels2 = [int(os.path.split(filename)[-1][0]) for filename in self.filenames]\n",
    "        #print(self.labels2)\n",
    "        self.labels = np.array([onehot(6,i) for i in self.labels2])\n",
    "        #self.filenames = data_dir[:,0]\n",
    "        #self.labels = data_dir[:,1]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # return size of dataset\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.filenames[idx])  # PIL image\n",
    "        #image = Image.open(self.filenames[idx]).convert('LA')  # PIL image\n",
    "        #image = ImageOps.equalize(image, mask = None)\n",
    "        image = self.transform(image)\n",
    "        return image,self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# th architecture to use\n",
    "arch = 'resnet18'\n",
    "\n",
    "# load the pre-trained weights\n",
    "model_file = '%s_places365.pth.tar' % arch\n",
    "if not os.access(model_file, os.W_OK):\n",
    "    weight_url = 'http://places2.csail.mit.edu/models_places365/' + model_file\n",
    "    os.system('wget ' + weight_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=365, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.__dict__[arch](num_classes=365)\n",
    "checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n",
    "state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "#print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in model.children():\n",
    "#     i.requires_grad = False\n",
    "    \n",
    "# model.fc =  torch.nn.Sequential(\n",
    "#             torch.nn.Linear(in_features=512, out_features=128, bias=True),\n",
    "#             torch.nn.ReLU(inplace=True),\n",
    "#             torch.nn.Linear(in_features=128, out_features=64, bias=True))\n",
    "\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the class label\n",
    "file_name = 'categories_places365.txt'\n",
    "if not os.access(file_name, os.W_OK):\n",
    "    synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt'\n",
    "    os.system('wget ' + synset_url)\n",
    "classes = list()\n",
    "with open(file_name) as class_file:\n",
    "    for line in class_file:\n",
    "        classes.append(line.strip().split(' ')[0][3:])\n",
    "classes = tuple(classes)\n",
    "\n",
    "#print(np.array(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test image\n",
    "img_name = '12.jpg'\n",
    "if not os.access(img_name, os.W_OK):\n",
    "    img_url = 'http://places.csail.mit.edu/demo/' + img_name\n",
    "    os.system('wget ' + img_url)\n",
    "\n",
    "img = Image.open(img_name)\n",
    "input_img = V(centre_crop(img).unsqueeze(0))\n",
    "\n",
    "# forward pass\n",
    "logit = model.forward(input_img)\n",
    "\n",
    "#print(logit)\n",
    "h_x = F.softmax(logit, 1).data.squeeze()\n",
    "\n",
    "probs, idx = h_x.sort(0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18 prediction on 12.jpg\n",
      "0.621 -> patio\n",
      "tensor(259)\n",
      "0.296 -> restaurant_patio\n",
      "tensor(286)\n",
      "0.021 -> porch\n",
      "tensor(272)\n",
      "0.018 -> beer_garden\n",
      "tensor(53)\n",
      "0.012 -> courtyard\n",
      "tensor(109)\n"
     ]
    }
   ],
   "source": [
    "print('{} prediction on {}'.format(arch,img_name))\n",
    "# output the prediction\n",
    "for i in range(0, 5):\n",
    "    print('{:.3f} -> {}'.format(probs[i], classes[idx[i]]))\n",
    "    print(idx[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu().eval()\n",
    "example = torch.rand(1, 3, 256, 256)\n",
    "traced_script_module = torch.jit.trace(model, example)\n",
    "traced_script_module.save(\"model_scope.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
